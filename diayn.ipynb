{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "import gymnasium as gym\n",
    "from gymnasium.wrappers import RecordVideo\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from config import get_config\n",
    "\n",
    "from policy import CategoricalPolicy, GaussianPolicy\n",
    "from network_utils import build_mlp, np2torch\n",
    "\n",
    "from ppo import PPO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# configurations\n",
    "env_name = 'cheetah'\n",
    "seed = 137\n",
    "use_baseline = True\n",
    "ppo = True\n",
    "\n",
    "config = get_config(env_name, use_baseline, ppo, seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniconda/base/envs/cs234_hw3/lib/python3.8/site-packages/gymnasium/envs/registration.py:513: DeprecationWarning: \u001b[33mWARN: The environment HalfCheetah-v2 is out of date. You should consider upgrading to version `v4`.\u001b[0m\n",
      "  logger.deprecation(\n",
      "/opt/homebrew/Caskroom/miniconda/base/envs/cs234_hw3/lib/python3.8/site-packages/gymnasium/envs/mujoco/mujoco_env.py:211: DeprecationWarning: \u001b[33mWARN: This version of the mujoco environments depends on the mujoco-py bindings, which are no longer maintained and may stop working. Please upgrade to the v4 versions of the environments (which depend on the mujoco python bindings instead), unless you are trying to precisely replicate previous works).\u001b[0m\n",
      "  logger.deprecation(\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "expected np.ndarray (got tuple)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 7\u001b[0m\n\u001b[1;32m      5\u001b[0m env \u001b[38;5;241m=\u001b[39m gym\u001b[38;5;241m.\u001b[39mmake(config\u001b[38;5;241m.\u001b[39menv_name)\n\u001b[1;32m      6\u001b[0m model \u001b[38;5;241m=\u001b[39m PPO(env, config, seed)\n\u001b[0;32m----> 7\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/Stanford/Class Materials/Spring 2024/cs234/cs234/policy_gradient.py:390\u001b[0m, in \u001b[0;36mPolicyGradient.run\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    388\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrecord()\n\u001b[1;32m    389\u001b[0m \u001b[38;5;66;03m# model\u001b[39;00m\n\u001b[0;32m--> 390\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    391\u001b[0m \u001b[38;5;66;03m# record one game at the end\u001b[39;00m\n\u001b[1;32m    392\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mrecord:\n",
      "File \u001b[0;32m~/Documents/Stanford/Class Materials/Spring 2024/cs234/cs234/ppo.py:86\u001b[0m, in \u001b[0;36mPPO.train\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     81\u001b[0m averaged_total_rewards \u001b[38;5;241m=\u001b[39m []  \u001b[38;5;66;03m# the returns for each iteration\u001b[39;00m\n\u001b[1;32m     83\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mnum_batches):\n\u001b[1;32m     84\u001b[0m \n\u001b[1;32m     85\u001b[0m     \u001b[38;5;66;03m# collect a minibatch of samples\u001b[39;00m\n\u001b[0;32m---> 86\u001b[0m     paths, total_rewards \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msample_path\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43menv\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     87\u001b[0m     all_total_rewards\u001b[38;5;241m.\u001b[39mextend(total_rewards)\n\u001b[1;32m     88\u001b[0m     observations \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mconcatenate([path[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mobservation\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m path \u001b[38;5;129;01min\u001b[39;00m paths])\n",
      "File \u001b[0;32m~/Documents/Stanford/Class Materials/Spring 2024/cs234/cs234/ppo.py:166\u001b[0m, in \u001b[0;36mPPO.sample_path\u001b[0;34m(self, env, num_episodes)\u001b[0m\n\u001b[1;32m    163\u001b[0m states\u001b[38;5;241m.\u001b[39mappend(state)\n\u001b[1;32m    164\u001b[0m \u001b[38;5;66;03m# Note the difference between this line and the corresponding line\u001b[39;00m\n\u001b[1;32m    165\u001b[0m \u001b[38;5;66;03m# in PolicyGradient.\u001b[39;00m\n\u001b[0;32m--> 166\u001b[0m action, old_logprob \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpolicy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mact\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstates\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_log_prob\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    167\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;28mtype\u001b[39m(action), \u001b[38;5;28mtype\u001b[39m(old_logprob))\n\u001b[1;32m    168\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m old_logprob\u001b[38;5;241m.\u001b[39mshape \u001b[38;5;241m==\u001b[39m (\u001b[38;5;241m1\u001b[39m,)\n",
      "File \u001b[0;32m~/Documents/Stanford/Class Materials/Spring 2024/cs234/cs234/policy.py:43\u001b[0m, in \u001b[0;36mBasePolicy.act\u001b[0;34m(self, observations, return_log_prob)\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mact\u001b[39m(\u001b[38;5;28mself\u001b[39m, observations, return_log_prob \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[1;32m     27\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     28\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[1;32m     29\u001b[0m \u001b[38;5;124;03m        observations: np.array of shape [batch size, dim(observation space)]\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[38;5;124;03m    https://pytorch.org/docs/stable/distributions.html\u001b[39;00m\n\u001b[1;32m     42\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m---> 43\u001b[0m     observations \u001b[38;5;241m=\u001b[39m \u001b[43mnp2torch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobservations\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     44\u001b[0m     \u001b[38;5;66;03m#######################################################\u001b[39;00m\n\u001b[1;32m     45\u001b[0m     \u001b[38;5;66;03m#########   YOUR CODE HERE - 1-4 lines.    ############\u001b[39;00m\n\u001b[1;32m     46\u001b[0m     dist \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maction_distribution(observations)\n",
      "File \u001b[0;32m~/Documents/Stanford/Class Materials/Spring 2024/cs234/cs234/network_utils.py:56\u001b[0m, in \u001b[0;36mnp2torch\u001b[0;34m(x, cast_double_to_float)\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mnp2torch\u001b[39m(x, cast_double_to_float\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[1;32m     50\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     51\u001b[0m \u001b[38;5;124;03m    Utility function that accepts a numpy array and does the following:\u001b[39;00m\n\u001b[1;32m     52\u001b[0m \u001b[38;5;124;03m        1. Convert to torch tensor\u001b[39;00m\n\u001b[1;32m     53\u001b[0m \u001b[38;5;124;03m        2. Move it to the GPU (if CUDA is available)\u001b[39;00m\n\u001b[1;32m     54\u001b[0m \u001b[38;5;124;03m        3. Optionally casts float64 to float32 (torch is picky about types)\u001b[39;00m\n\u001b[1;32m     55\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m---> 56\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_numpy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m     57\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m cast_double_to_float \u001b[38;5;129;01mand\u001b[39;00m x\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;129;01mis\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mfloat64:\n\u001b[1;32m     58\u001b[0m         x \u001b[38;5;241m=\u001b[39m x\u001b[38;5;241m.\u001b[39mfloat()\n",
      "\u001b[0;31mTypeError\u001b[0m: expected np.ndarray (got tuple)"
     ]
    }
   ],
   "source": [
    "torch.random.manual_seed(seed)\n",
    "np.random.seed(seed)\n",
    "random.seed(seed)\n",
    "\n",
    "env = gym.make(config.env_name)\n",
    "model = PPO(env, config, seed)\n",
    "model.run()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cs234_hw3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
